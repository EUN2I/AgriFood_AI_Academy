{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 통계 vs 머신러닝\n","\n","<img src = \"https://d1m75rqqgidzqn.cloudfront.net/2019/10/What-is-Machine-Learning-Machine-learning-model-vs-traditional-model.jpg\"  width=700>\n","\n","<img src = \"https://www.datocms-assets.com/14946/1596797558-da-vs-ds-diagram.png\" width = 600>"],"metadata":{"id":"qBce9BBuVTfb"}},{"cell_type":"markdown","source":["# 머신러닝 (지도학습)의 과정\n","\n","<img src = \"https://blogs.nvidia.com/wp-content/uploads/2018/07/Supervised_machine_learning_in_a_nutshell.svg_.png\" width = 700>"],"metadata":{"id":"w4kUkwRtWmGo"}},{"cell_type":"markdown","source":["# 사이킷런 라이브러리\n","\n","<img src = \"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\">"],"metadata":{"id":"L3iajaY3J_Bu"}},{"cell_type":"markdown","source":["- 공식 문서: https://scikit-learn.org/stable/index.html\n","\n","\n","- scikit = SciPy + Toolkit\n","\n","\n","- 한국어 버전 (1.1 버전): https://runebook.dev/ko/docs/scikit_learn/-index-\n","\n","- 한국어 cheatsheet: https://www.facebook.com/groups/KerasKorea/posts/2304357519580200/"],"metadata":{"id":"BT5dTxUzJcFl"}},{"cell_type":"markdown","source":["<img src = \"https://scikit-learn.org/stable/_static/ml_map.png\">"],"metadata":{"id":"VTdWSlq4JoH4"}},{"cell_type":"markdown","source":["<img src = \"https://t1.daumcdn.net/cfile/tistory/99DBBD385B7811A815?download\">\n"],"metadata":{"id":"O01yTSb2-A53"}},{"cell_type":"markdown","source":["#scikit-learn 버전 확인\n","\n","- sklearn은 버전 확인이 중요하다\n","- 중간중간 업데이트가 많아서 버전 업데이트 안하면 에러날 수도 있음"],"metadata":{"id":"JbPO7MNW_xTw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"0DA4mW0uHsJj"},"outputs":[],"source":["import sklearn"]},{"cell_type":"code","source":["sklearn.__version__"],"metadata":{"id":"iGwqvj1dIl3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns"],"metadata":{"id":"Pnr1xiewK3tn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# sklearn 내장 데이터\n","https://scikit-learn.org/stable/datasets.html"],"metadata":{"id":"7gx2tNEipei9"}},{"cell_type":"code","source":["from sklearn import datasets"],"metadata":{"id":"g4g8TjunyBZF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#toy datasets 목록\n","\n","datasets.load_*?"],"metadata":{"id":"ZfTOsSbfyg2l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Real world datasets 목록\n","\n","datasets.fetch_*?"],"metadata":{"id":"0CtEnBUO745N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Iris (붓꽃) 데이터\n","<img src = \"https://miro.medium.com/max/1400/0*SHhnoaaIm36pc1bd\" width = 700>\n","\n","<br>\n","\n","- 설명: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris\n","\n","## 1.  **sample** (로우, 인스턴스, 관찰값): 150개\n"," - 클래스 당 50개\n","\n","## 2.  **feature** (피처, 칼럼): 4개 \n","\n"," - sepal length (꽃받침의 길이)\n"," - sepal width (꽃받침의 넓이)\n"," - petal lenth (꽃잎의 길이)\n"," - petal width (꽃잎의 넓이)\n","\n","## 3. **class label** (타깃, 레이블, 정답): 3개\n","\n"," 1) Setosa\n","   <br> <img src = \"https://www.plant-world-seeds.com/images/item_images/000/007/023/large_square/iris_baby_blue.jpg?1500653527\" width = 200><br>\n"," 2) Versicolour\n","   <br><img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Iris_versicolor_4.jpg/1200px-Iris_versicolor_4.jpg\" width = 200><br>\n"," 3) Virginica\n","   <br><img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/f/f8/Iris_virginica_2.jpg/1200px-Iris_virginica_2.jpg\" width = 200>\n","\n","## 4. **attribute** (피처 + 타깃)"],"metadata":{"id":"1vgsUOfrMH2z"}},{"cell_type":"markdown","source":["# 데이터 임포트"],"metadata":{"id":"ZJ8fZyTmMgxR"}},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","\n","iris = load_iris()"],"metadata":{"id":"aycdKquRIp5W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris"],"metadata":{"id":"cJnZvCP7Cp_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import datasets\n","\n","iris = datasets.load_iris()"],"metadata":{"id":"KFdRTA-YKrGM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris"],"metadata":{"id":"DSjr5vpZH2iC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.head(5) #오류 #Bunch 타입의 데이터이기 때문"],"metadata":{"id":"U3KYos5NEVVb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(iris) #Bunch #Dictionary-like object"],"metadata":{"id":"1btZMZ09MfUN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(iris.data)"],"metadata":{"id":"vYzjj6HcR7yy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(iris.target)"],"metadata":{"id":"YAk63kfUR_tG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.data #.data #피처별 샘플"],"metadata":{"id":"ne_dvYr1NTbP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.target #target #타깃 # 0 = setosa, 1 = versicolor, 2 = virginica"],"metadata":{"id":"5RZfO_KYSEPE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.feature_names #피처 이름"],"metadata":{"id":"P7BgyBwdFWPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.target_names #타깃 이름 #클래스 레이블"],"metadata":{"id":"y7zzDH6_FANG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(iris.DESCR) #데이터 설명"],"metadata":{"id":"YtLIDxCbFf-I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.data.shape #샘플과 피처의 갯수"],"metadata":{"id":"ztqxraymSHun"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["iris.target.shape #타깃의 갯수"],"metadata":{"id":"pvVmKHGkSLxm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 데이터프레임으로 바꿔주기"],"metadata":{"id":"_Tagvgr_PeEN"}},{"cell_type":"code","source":["df = pd.DataFrame(iris.data, columns = iris.feature_names)\n","\n","df['target'] = iris.target \n","\n","df.head()"],"metadata":{"id":"Zambf4fALFKl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2 = df.rename(columns={'sepal length (cm)' : 'sepal_length', \n","                        'sepal width (cm)'  : 'sepal_width',\n","                        'petal length (cm)' : 'petal_length',\n","                        'petal width (cm)'  : 'petal_width'\n","                       })"],"metadata":{"id":"cqfSvmZE-i8U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.info()"],"metadata":{"id":"t9KI7DZD--6D"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.describe()"],"metadata":{"id":"KC4IIZv__Ua6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.groupby('target').agg(['mean', 'median'])"],"metadata":{"id":"-rqSY9qdXqRw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df2.to_csv('iris.csv') #내보내기"],"metadata":{"id":"I29aLpb69UwZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import seaborn as sns\n","\n","iris = sns.load_dataset(\"iris\")\n","\n","print(iris.head())"],"metadata":{"id":"dF9YKV84HxrQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 시각화를 통한 데이터 살펴보기"],"metadata":{"id":"4E220rva-Hbc"}},{"cell_type":"code","source":["df2.plot(x = \"sepal_length\", y = \"petal_length\", kind = \"scatter\")"],"metadata":{"id":"gDY2HVKi-HBJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 박스 플랏\n","\n","sns.boxplot(data = df2, x = \"target\", y = \"petal_length\")"],"metadata":{"id":"qPhfvdqA_5qz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 박스 플랏\n","\n","df2.boxplot(by = \"target\", \n","            figsize=(13, 7.5))"],"metadata":{"id":"v-j7s-cGCbK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 패어 플랏 (pairplot)\n","\n","sns.pairplot(df2, \n","             hue = \"target\", \n","             kind = 'scatter', \n","             palette=\"tab10\", \n","             height = 2.5, \n","             markers=[\"o\", \"s\", \"D\"])\n","\n","# palette 색 이름 : https://seaborn.pydata.org/tutorial/color_palettes.html?highlight=rocket"],"metadata":{"id":"2-8E4C8GAO-U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# training 데이터와 test 데이터의 램던한 분리 \n","\n","- train_test_split(x,y)\n"," - x: 피처 (iris 데이터의 경우에는 iris.data)\n"," - y: 타깃 (iris 데이터의 경우에는 iris.target)"],"metadata":{"id":"EK0KtOaJOQ1Z"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"g9_CnRT0WY9N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(iris.data, \n","                                                    iris.target, \n","                                                    test_size = 0.25, \n","                                                    random_state = 42, \n","                                                    shuffle = True, \n","                                                    stratify = iris.target)\n","\n","# X_train = 훈련용 피처 데이터\n","# X_test = 테스트용 피처 데이터\n","# y_train = 훈련용 타깃 데이터\n","# y_test = 테스트용 타깃 데이터\n","\n","#############\n","\n","# test_size: 훈련 데이터 대비 테스트 데이터의 램덤 분할 (shuffle) 비율\n","\n","# random_state: 동일한 데이터들이 매번 훈련 데이터와 테스트 데이터에 할당되도록 지정해주는 값. \n","# 아무런 값을 입력해도 괜찮으나 보통 0과 42를 선호. \n","# 타인과 공유시 모델의 재현 가능성 (reproducibility)을 담보해줌.\n","\n","# shuffle: 랜덤하게 섞는다는 뜻. False일 경우 stratify 는 None 으로 설정해야.\n","\n","# stratify: 층을 나눈다는 뜻. 값을 지정해줄 경우 타깃의 클래스 마다 동일한 비율로 분할. 데이터가 불균형하게 레이블링 되어 있을 경우 사용.  "],"metadata":{"id":"ELFAJeETUSFs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train.shape"],"metadata":{"id":"kbIJDZ5xMQR2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train.shape"],"metadata":{"id":"0CToGVzFMTdl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test.shape"],"metadata":{"id":"TywOaOSSMTWc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"id":"oBAS9ccMMTMq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["38/112"],"metadata":{"id":"4y5tbobbMb_b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#만약 Bunch 형태가 아닌 데이터프레임 형태의 데이터일 경우 X데이터와 y데이터 나누기\n","\n","X_df = df2.iloc[:, :-1].values\n","y_df = df2.iloc[:, 4].values\n","\n","X_df_train, X_df_test, y_df_train, y_df_test = train_test_split(X_df, \n","                                                                y_df, \n","                                                                test_size = 0.25, \n","                                                                random_state = 42, \n","                                                                shuffle = True)"],"metadata":{"id":"fPHlf_sGQ2c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_df_train"],"metadata":{"id":"yj96TDzfRBvF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_df_train.shape"],"metadata":{"id":"FI30eC9fWfQb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_df_test.shape"],"metadata":{"id":"pIaJUr59WgIi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_df_train.shape"],"metadata":{"id":"0-_4g7m3Wk0m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.shape"],"metadata":{"id":"XHwzJwZ-Wme7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##데이터간 차이와 왜곡를 줄이기 위한 피처 스케일링\n","\n","### Standardization vs. Normalization\n","<img src = \"https://lh3.googleusercontent.com/HYYaWfQLnk5HLW_rtRcSRmKwBFpn4VRSEigjoJgEYrt3CC-EZkVE38mijNpBZJOFUibaYL8SxA7YqrBT8ilDLftxzF4bHk5vBKfC9CzB42ccBq7vmOUDchh3mb9TjNRcP-Z3x4iD\">\n","\n","<img src = \"https://storage.googleapis.com/algodailyrandomassets/curriculum/standvsnorm/comparison_graph.png\">\n","\n","### 방법 1) 표준정규분포화 (standardization) \n","\n","- 변형 후 값의 범위: [-무한대:+무한대] \n","- 평균(μ) = 0, 표준편차(σ) = 1\n","- 해당 함수 (1): (x-mean())/std() \n","- 해당 함수 (2): ss.zscore() \n","- 해당 함수 (3): StandardScaler().fit_transform()\n","- 링크: https://rfriend.tistory.com/268\n","\n","<img src = \"https://t1.daumcdn.net/cfile/tistory/2428EB4658500BB61B\">\n","\n","### 방법 2) 최소 최대 `0~1` 범위 변환 (normalization) <br>\n","- 변형 후 값의 범위: [0:1]\n","- scaling individual samples to have unit norm\n","- 해당 함수: sklearn.preprocessing.MinMaxScaler() <br>\n","- 링크: https://rfriend.tistory.com/270\n","\n","<img src = \"https://t1.daumcdn.net/cfile/tistory/2741F74B5853FDA131\">\n","\n","### 방법 2) 이상치가 포함된 데이터의 중앙값과 IQR 를 이용한 표준화\n","- 해당 함수: StandardScaler().RobustScaler()\n","- 링크: https://rfriend.tistory.com/269\n","\n","<img src = \"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Ft1.daumcdn.net%2Fcfile%2Ftistory%2F241197355852AE9003\">\n","\n"],"metadata":{"id":"0T__ORSxTWLO"}},{"cell_type":"code","source":["#데이터 분할 이후 권장\n","\n","from sklearn.preprocessing import StandardScaler \n","\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train_t = scaler.transform(X_train)\n","X_test_t = scaler.transform(X_test)"],"metadata":{"id":"vTKWpbD0S9KH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train #첫 훈련 데이터와 비교"],"metadata":{"id":"SS8cxegKTEAT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.distplot(X_train_t)"],"metadata":{"id":"jfrSHoE3QbVN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train_t.min(), X_train_t.max(), format(X_train_t.mean(), 'f'))"],"metadata":{"id":"Rx-guG0aO2Au"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test #첫 실험 데이터와 비교"],"metadata":{"id":"HGtvcOq1TGLA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_test_t.min(), X_test_t.max(), format(X_test_t.mean(), 'f'))"],"metadata":{"id":"gotuJS1kSVt1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sns.distplot(X_test_t)"],"metadata":{"id":"y4IUTBzQSJVa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Classification - 분류 모델 만들기"],"metadata":{"id":"uF6i12cM9xIK"}},{"cell_type":"markdown","source":["## 로지스틱 회귀 분석"],"metadata":{"id":"VeAbKrNnDTgl"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"KDOGvLNODYJG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 훈련 및 테스트\n","\n","L_clf = LogisticRegression(random_state=42).fit(X_train, y_train) #로지스틱 모델  #classifier를 줄여서 clf로 흔히 표현\n","\n","y_pred = L_clf.predict(X_test) #훈련된 모델에 테스트용 입력 데이터 넣어 예측값 생성"],"metadata":{"id":"n98R2cS0-Bzn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred #예측된 값"],"metadata":{"id":"rCer3t7LTSOR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test #실제 값"],"metadata":{"id":"8t-NTtG0UWtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#분류 결과\n","\n","from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred))\n","\n","#support = 각 클래스의 실제 샘플 갯수\n","\n","#macro avg = 각 클래스의 데이터 불균형을 고려하지 않은 평균 수치\n","\n","#weighted avg = 각 클래스의 데이터 불균형을 고려한 평균 수치"],"metadata":{"id":"Z8EokHQo-BxA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src = \"https://2.bp.blogspot.com/-uCi_IXC-5C0/W4lDTCG8SnI/AAAAAAAABIo/kxasPdWoA107m1qazYXvHsCy6Q9h1QBSwCEwYBhgL/s1600/xxx.png\" width = 500>\n","\n","<img src = \"https://d3i71xaburhd42.cloudfront.net/e4817d541f3dd735621df62b1805c895195f8528/2-Table1-1.png\" width = 500>\n","\n","- Recall = True positive rate (TPR)\n","- Sensitivity = Recall = TPR\n","- Specificity = True negative rate (TNR)\n","- 1 - Specificity = False Positive rate (FPR)"],"metadata":{"id":"9OUuvgZYJlBZ"}},{"cell_type":"markdown","source":["<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/1280px-Precisionrecall.svg.png\" width = 350> <img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Sensitivity_and_specificity_1.01.svg/683px-Sensitivity_and_specificity_1.01.svg.png\" width = 350>"],"metadata":{"id":"LU3dDyBQMXPu"}},{"cell_type":"code","source":["#confusion matrix 출력\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","print(confusion_matrix(y_test, y_pred, labels = L_clf.classes_))\n","\n","#y축 = 각 클래스의 실제 분류 결과\n","#x축 = 각 클래스의 예측 분류 결과\n"],"metadata":{"id":"VdOB-xA9D6TP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src = \"https://i.stack.imgur.com/0yLu8.png\">"],"metadata":{"id":"gCHVSQBHJz_x"}},{"cell_type":"code","source":["#confusion matrix 시각화\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","cm = confusion_matrix(y_test, y_pred, labels = L_clf.classes_)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n","                              display_labels = L_clf.classes_)\n","\n","fig, ax = plt.subplots(figsize = (10,10))\n","\n","disp.plot(ax = ax)\n","\n","plt.show()"],"metadata":{"id":"5NTmS5a4GIg7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#accuracy만 출력할 경우\n","\n","from sklearn.metrics import accuracy_score\n","\n","print('accuracy :', format(accuracy_score(y_pred, y_test), '.4f'))"],"metadata":{"id":"ZAf0z99r-Buy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 로지스틱 분류 모델의 여러 종류\n","\n","- 로지스틱 (LR) 분류 = 여러 IV, 하나의 DV (binary)\n","\n","- Multi class LR = 여러 IV, 하나의 DV (여러 클래스 중 하나를 선택)\n","\n","- Multinomial LR = Multi class LR = Softmax 회귀\n","\n","- Multi label LR = 여러 IV, 여러 DV (여러 클래스 중 여러 개 선택)\n","\n","- Multi output LR = Multi label LR\n","\n","- Multivariate LR = 여러 IV, 여러 DV\n","\n","- Multivariable LR = 여러 IV, 하나의 DV\n","\n","- Multiple LR = Multivariable 분류\n","\n","## <일타 스캔들>은 스릴러? 로맨스? 아니면 둘다?\n","\n","<img src = \"https://post-phinf.pstatic.net/MjAxOTEyMTFfMTc1/MDAxNTc2MDUwNTczODUx.e3Hy3NXM1ZxhTIKwflWj9z1MSYmCpnldcFAUj_IgRcUg.hm2LBSAy0Johs5LSdVG3FfGQi6-fufnF_qzr_O9OyXEg.PNG/191203_SKB_%EB%B8%94%EB%A1%9C%EA%B7%B8_%EB%A1%9C%EB%A7%A8%EC%8A%A4%EB%A6%B4%EB%9F%AC.png?type=w1200\" width = 700>\n","\n","\n"],"metadata":{"id":"vaSMALOg6vmn"}},{"cell_type":"markdown","source":["## `multi_class` parameter의 기본 설정은?\n","\n","https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n","\n","<img src = \"https://images.slideplayer.com/24/7086332/slides/slide_25.jpg\" width = 500>\n","\n","<img src = \"https://michael-fuchs-python.netlify.app/post/2019-11-15-multinomial-logistic-regression_files/p27s1.png\" width = 500>"],"metadata":{"id":"BVBND2lXCZY4"}},{"cell_type":"markdown","source":["# 결정 경계선 시각화\n","\n","- 1차원 결정 경계선 : 개별 피처의 값에 따른 클래스 구분\n","- 2차원 결정 경계선 : 2개 피처의 값에 따른 클래스 구분 "],"metadata":{"id":"Fy5NH7xDcJLg"}},{"cell_type":"code","source":["!pip install mlxtend --upgrade\n","\n","#이후 Restart runtime 실행"],"metadata":{"id":"ApKDTUFCYu-7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import mlxtend"],"metadata":{"id":"gpLnPJ9yZnsY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mlxtend.__version__"],"metadata":{"id":"12TPlDtCZipn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from mlxtend.plotting import plot_decision_regions"],"metadata":{"id":"VYRsgXQYcfrW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.datasets import load_iris\n","\n","iris = load_iris()"],"metadata":{"id":"7WPzQ9UgaKbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns"],"metadata":{"id":"xPUrYV8Qa2tb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 1차원 결정 경계선 - 1개 피처만 시각화\n"],"metadata":{"id":"5cNtSQvndcc_"}},{"cell_type":"code","source":["# 데이터 구분\n","\n","X1 = iris.data[:, 0] #sepal_length #1d 배열 상태\n","X1 = X1[:, None]     #1d 배열을 2d 배열로 변환 필요\n","\n","y = iris.target"],"metadata":{"id":"CNzgpjp-cXFY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X1.ndim"],"metadata":{"id":"D09BZhHZb6hZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 다른 피처들도 동일한 구분\n","\n","X2 = iris.data[:, 1] #sepal_width\n","X2 = X2[:, None]\n","\n","X3 = iris.data[:, 2] #petal_length\n","X3 = X3[:, None]\n","\n","X4 = iris.data[:, 3] #petal_width\n","X4 = X4[:, None]"],"metadata":{"id":"Ana69K93aaSV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"nHYrKBmBan4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 훈련 \n","\n","L_clf2 = LogisticRegression() \n","L_clf2.fit(X1, y)\n","\n","#시각화\n","ax = plot_decision_regions(X1, y, clf=L_clf2, legend=1)\n","\n","plt.xlabel('sepal length')\n","plt.title('Decision Boundary - Logistic Regression - 1D')\n","\n","#레전드\n","leg, labels = ax.get_legend_handles_labels()\n","ax.legend(leg, ['Setosa', 'Versicolor', 'Virginica'])\n","\n","plt.show()"],"metadata":{"id":"eMD90bZRUxR-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 2차원 결정 경계선 - 2개 피처를 시각화"],"metadata":{"id":"Yx9rsCOLe6NS"}},{"cell_type":"code","source":["# 데이터 구분\n","\n","X1 = iris.data[:, [0, 1]] #sepal_length & sepal_width의 경우\n","\n","y = iris.target"],"metadata":{"id":"55LROeFNfUUI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 훈련\n","\n","L_clf = LogisticRegression() \n","L_clf.fit(X1, y)\n","\n","#시각화\n","ax = plot_decision_regions(X1, y, clf=L_clf, legend=1)\n","\n","plt.xlabel('sepal length')\n","plt.ylabel('sepal_width')\n","plt.title('Decision Boundary - Logistic Regression - 2D')\n","\n","#레전드\n","leg, labels = ax.get_legend_handles_labels()\n","ax.legend(leg, ['Setosa', 'Versicolor', 'Virginica'])\n","\n","plt.show()"],"metadata":{"id":"DBMORW-1fUO8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### ROC  커브\n","\n","- TPR vs FPR의 비교를 통한 모델 성능 평가\n","- https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n","- [Source code](https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/metrics/_plot/roc_curve.py) "],"metadata":{"id":"yOI0Vz_iiNr2"}},{"cell_type":"markdown","source":["## Binary-class 타깃(종속변수)을 통한 ROC 커브 그리기\n","- diabetes (당뇨병) 데이터"],"metadata":{"id":"08teHzBfpuld"}},{"cell_type":"markdown","source":["<img src = \"https://www.cdc.gov/healthyweight/images/assessing/bmi-adult-fb-600x315.jpg?_=07167\">"],"metadata":{"id":"Maieuha3fx3m"}},{"cell_type":"code","source":["# 데이터 가져오기\n","\n","import pandas as pd \n","\n","dia = pd.read_csv('/content/diabetes.csv')\n","\n","dia.head(5)"],"metadata":{"id":"KxYRgGSLY_S5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#피처 (= X) 및 레이블 (= y) 할당\n","\n","features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age']\n","X = dia[features] \n","y = dia.Outcome"],"metadata":{"id":"pdlTk--nbw0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 분할 (= training와 test 데이터로)\n","\n","from sklearn.model_selection import train_test_split\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"],"metadata":{"id":"FtM531-tbw4-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 훈련\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","L_clf2 = LogisticRegression()\n","\n","L_clf2.fit(X_train, y_train)\n","\n","#training 데이터로 예측 실행\n","y_pred2 = L_clf2.predict(X_test)"],"metadata":{"id":"9tu2jDLubw6-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred2 #예측된 결과"],"metadata":{"id":"7tbgJQrcm03b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["np.unique(y_pred2, return_counts=True) #예측된 결과"],"metadata":{"id":"_C4dT8URbM0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test #실제 결과"],"metadata":{"id":"_XPIgdidbwSC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test.value_counts() #실제 결과"],"metadata":{"id":"ZMGm8r1fm0w2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('실제 test 데이터에 있는 레이블 :', y_test.values[0:30])\n","print('로지스틱 모델로 예측한 레이블   :', y_pred2[0:30])"],"metadata":{"id":"n6RjN1cApHGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#예측된 결과가 실제 결과를 얼마나 정확히 예측했는지 정확도 측정\n","\n","from sklearn import metrics\n","\n","print(metrics.accuracy_score(y_test, y_pred2))"],"metadata":{"id":"hvUHWDy5bw8r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix 구하기\n","\n","metrics.confusion_matrix(y_test, y_pred2)\n","\n","#y축 = 각 클래스의 실제 분류 결과\n","#x축 = 각 클래스의 예측 분류 결과\n","\n","#37 = true positive [1,1]\n","#14 = false positive [0, 1]\n","#116 = true negative [0, 0]\n","#25 = true negative [1, 0]"],"metadata":{"id":"V31VA6Lgm0ub"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["<img src = \"https://i.stack.imgur.com/0yLu8.png\">"],"metadata":{"id":"xECUv97xqjP0"}},{"cell_type":"code","source":["#confusion matrix 시각화\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","cm = confusion_matrix(y_test, y_pred2, labels = L_clf2.classes_)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n","                              display_labels = L_clf2.classes_)\n","\n","fig, ax = plt.subplots(figsize = (10,10))\n","\n","disp.plot(ax = ax)\n","\n","plt.show()"],"metadata":{"id":"92HpWsznrZw-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix 통해 TP, TN, FP, FN 구하기\n","\n","TruePositive = cm[1,1]\n","\n","FalsePositive = cm[0,1]\n","\n","TrueNegative = cm[0,0]\n","\n","FalseNegative = cm[1,0]\n","\n","print(\"True Positive  :\", TruePositive)\n","\n","print(\"False Positive :\", FalsePositive)\n","\n","print(\"True Negative  :\", TrueNegative)\n","\n","print(\"False Negative :\", FalseNegative)"],"metadata":{"id":"xOo_rNzbqFmo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["TPR = TruePositive  / (TruePositive + FalseNegative)\n","print(\"True Positive Rate :\", TPR)\n","\n","FPR = FalsePositive  / (FalsePositive + TrueNegative)\n","print(\"False Positive Rate :\", FPR)"],"metadata":{"id":"CNh-quJhtov3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#predict()와 predict_prob()의 차이\n","\n","#predict() = 훈련된 모델을 test 데이터에 적용해 실제 타깃 값 (레이블)을 예측\n","\n","#predict_prob() = 훈련된 모델을 test 데이터에 적용해 개별 test 데이터가 0과 1 두 클래스 중 각 클래스에 어떤 확률로 분류될지를 예측\n","\n","print(L_clf2.predict(X_test)[0:5])\n","print(\"---\")\n","print(L_clf2.predict_proba(X_test)[0:5])\n","\n","\"\"\"\n","첫 row는 8.6%의 확률로 0 클래스, 91.4% 확률로 1 클래스 \n","두번째 row는 82.6% 확률로 0 클래스, 17.4% 확률로 1 클래스\n","이하 동일하게 해석\n","\n","즉 분류 기준 (threshold) = 50%임\n","이 분류 기준을 높이거나 낮춤에 따라 TPR, FPR도 달라짐\n","\"\"\"\n"],"metadata":{"id":"N28HUUHbqFk6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L_clf2.predict_proba(X_test)[:, 1] "],"metadata":{"id":"SoQsUWcr6Jve"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 피처 양분화 (Feature binarization)\n","# 분류 기준을 바꾸기 (50%가 아닌 70%가 넘어야 1 클래스로 분류함)\n","\n","from sklearn.preprocessing import binarize\n","\n","y_pred2_prob = L_clf2.predict_proba(X_test) \n","\n","y_pred2_class = binarize(y_pred2_prob, threshold = 0.7)"],"metadata":{"id":"4tXuZmAYw0c4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred2_prob"],"metadata":{"id":"ig4B3-d6gf7I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred2_class"],"metadata":{"id":"C56FfsRBoz9w"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred2_class[:, 0]"],"metadata":{"id":"U0TR0YtEw0WA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred2_class[:, 1]"],"metadata":{"id":"ebnxrkpAw0Q_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm = confusion_matrix(y_test, y_pred2)\n","print(cm) #분류 기준이 50%일 때"],"metadata":{"id":"ovzhTalMw0PL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","y_pred2_class=np.argmax(y_pred2_class, axis=1) #소수점 형태로 예측된 클래스 값을 정수 형태로 변환\n","y_pred2_class"],"metadata":{"id":"iJyPWrmg-hnq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"id":"yrQAE_u6g1pJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cm2 = metrics.confusion_matrix(y_test, y_pred2_class)\n","print(cm2) #분류 기준이 70%일 때\n","\n","#분류 기준을 40%로 바꾸면?"],"metadata":{"id":"PsJlRBgzw0IC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#roc.curve 함수 이용해 FPR, TPR 구하기\n","\n","#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html?highlight=roc_curve#sklearn.metrics.roc_curve\n","\n","fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2_prob[:, 1], pos_label=1)"],"metadata":{"id":"O-iiWiVmgASU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#roc_curve 결과값 살펴보기\n","\n","metrics.roc_curve(y_test, y_pred2_prob[:, 1], pos_label=1)"],"metadata":{"id":"DHdj4j91hQIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#fpr, tpr, thresholds로 각각 할당하기\n","\n","fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred2_prob[:, 1], pos_label=1)"],"metadata":{"id":"WHMPb58zkK7A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(fpr)\n","type(tpr)\n","type(thresholds)"],"metadata":{"id":"LrfW1efHkYKe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["fpr"],"metadata":{"id":"83FZJ-uchGse"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tpr"],"metadata":{"id":"-ObW6Lj0hJBT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["thresholds"],"metadata":{"id":"jVBV5EBahLGo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# thresholds는 실제 ROC 커브 시각화에 쓰이지 않으므로 아래처럼 언더바로 '버림' 처리하기도 함\n","\n","fpr, tpr, _ = metrics.roc_curve(y_test, y_pred2_prob[:, 1], pos_label=1) "],"metadata":{"id":"6hLR5nzrk8Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(6,6))\n","\n","plt.plot(fpr, tpr)\n","plt.plot([0, 1], [0, 1], 'k--', lw = 1) #랜덤 선택을 나타내는 검은색 점선\n","\n","plt.xlim([-0.05, 1.0])\n","plt.ylim([0.0, 1.05])\n","\n","plt.title('ROC curve - diabetes classification')\n","plt.xlabel('False Positive Rate (1 - Specificity)')\n","plt.ylabel('True Positive Rate (Sensitivity)')\n","\n","plt.grid(True)"],"metadata":{"id":"AmWs-HerqFg3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## AUC 구하기"],"metadata":{"id":"GdEXwFQsyLcf"}},{"cell_type":"code","source":["#데이터 가져와서 피처와 타깃별로 나누기\n","import pandas as pd \n","dia = pd.read_csv('/content/diabetes.csv')\n","\n","#피처 (= X) 및 타깃 (= y) 할당\n","features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'Age']\n","X = dia[features] \n","y = dia.Outcome\n","\n","#데이터 분할\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n","\n","#데이터 스케일링\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","#모델 훈련 \n","from sklearn.linear_model import LogisticRegression\n","L_clf2 = LogisticRegression()\n","L_clf2.fit(X_train, y_train)\n","\n","#모델 적용 후 test 데이터별 확률\n","y_pred2_prob = L_clf2.predict_proba(X_test) \n","\n","#AUC 계산\n","print(metrics.roc_auc_score(y_test, y_pred2_prob[:, 1]))"],"metadata":{"id":"ACWR51LOw7Bo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multi-class 타깃(종속변수)을 통한 ROC 커브 그리기\n","- Iris 데이터"],"metadata":{"id":"YaTsQd9Bl-Ut"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import label_binarize\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.multiclass import OneVsRestClassifier\n","from itertools import cycle\n","\n","# 데이터 가져와서 피처와 타깃별로 나누기\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# 타깃을 binary하게\n","y = label_binarize(y, classes=[0, 1, 2])"],"metadata":{"id":"-ZuRZxJ0RCGe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# binary하게 잘 표기되었는지 y 확인하기\n","y"],"metadata":{"id":"i1nYiPxXoCJQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n","\n","L_clf3 = OneVsRestClassifier(LogisticRegression()) \n","#멀티 클래스 분류를 binary 클래스 분류 모델로 변환\n","\n","y_score = L_clf3.fit(X_train, y_train).decision_function(X_test) \n","#훈련데이터로 훈련시킨 모델을 테스트 데이터에 적용한 결과 \n","#decision boundary에서부터의 차이"],"metadata":{"id":"42k0FmtBVYO0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_score "],"metadata":{"id":"zMad-G43VrEM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ROC 커브 시각화\n","fpr = dict()\n","tpr = dict()\n","roc_auc = dict()\n","n_classes = y.shape[1]\n","\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])  \n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","plt.figure(figsize=(6,6))\n","\n","colors = cycle([\"aqua\", \"darkorange\", \"cornflowerblue\"])\n","\n","for i, color in zip(range(n_classes), colors):\n","    plt.plot(fpr[i], tpr[i], color = color, lw = 1,\n","             label='ROC curve of class {0} (area = {1:0.2f})'\n","             ''.format(i, roc_auc[i]))\n","\n","plt.plot([0, 1], [0, 1], 'k--', lw = 1) #랜덤 선택을 나타내는 검은색 점선\n","\n","plt.xlim([-0.05, 1.0])\n","plt.ylim([0.0, 1.05])\n","\n","plt.xlabel('False Positive Rate (1-Specificity)')\n","plt.ylabel('True Positive Rate (Sensitivity)')\n","\n","plt.title('ROC Curve - Iris')\n","plt.legend(loc=\"lower right\")\n","\n","plt.show()"],"metadata":{"id":"6jVhRzJhn052"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L_clf3.coef_"],"metadata":{"id":"kJeAEPf6oCNm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["L_clf3.coef_[0]"],"metadata":{"id":"T8Kuwoqmp3Cg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Class 0 (Setosa 종)의 피처별 중요도\n","\n","importance = L_clf3.coef_[0]\n","\n","#각 피쳐별 중요도\n","\n","for i,v in enumerate(importance):\n","\tprint('피처: %0d, 중요도: %.5f' % (i,v))\n"," \n","#시각화\n","\n","plt.figure(figsize=(8,4))\n","plt.bar([x for x in range(len(importance))], importance)\n","\n","plt.xticks([0, 1, 2, 3],\n","           ['sepal length', 'sepal width', 'petal length', 'petal width'],\n","           rotation = 45)\n","\n","plt.title(\"Feature Importance - Class 0 (Setosa)\")\n","plt.show()"],"metadata":{"id":"S8hwbqsDnnOF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2번째 방법 - 삭제 필요\n","\n",">>> import scikitplot.plotters as skplt\n",">>> rf = RandomForestClassifier()\n",">>> rf.fit(X, y)\n",">>> skplt.plot_feature_importances(\n","...     rf, feature_names=['petal length', 'petal width',\n","...                        'sepal length', 'sepal width'])\n","<matplotlib.axes._subplots.AxesSubplot object at 0x7fe967d64490>\n",">>> plt.show()"],"metadata":{"id":"DqXzgbDxuEvz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# K-최근접 이웃 분류 모델 (K-nearest neighbors, KNN)\n","\n","<img src = \"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/KnnClassification.svg/220px-KnnClassification.svg.png\" width = 400>"],"metadata":{"id":"Bb_Sl_yzQGBp"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","import numpy as np"],"metadata":{"id":"Yrj6FnSxtRg-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터 가져와서 피처와 타깃별로 나누기\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","#데이터 할당\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state = 12)"],"metadata":{"id":"QHU31jBRqhWo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#데이터간 차이를 평균화하기 위한 피처 스케일링\n","\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","scaler.fit(X_train)\n","\n","X_train = scaler.transform(X_train)\n","X_test = scaler.transform(X_test)"],"metadata":{"id":"DptdkyVg-Btt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","\n","K_clf = KNeighborsClassifier(n_neighbors = 5) #K = 5\n","\n","K_clf.fit(X_train, y_train)"],"metadata":{"id":"FzZdvGJN-Brg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = K_clf.predict(X_test)"],"metadata":{"id":"FNTdVoUv-Bp-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix 출력\n","\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","\n","print(confusion_matrix(y_test, y_pred, labels=K_clf.classes_))\n","\n","#y축 = 각 클래스의 실제 분류 결과\n","#x축 = 각 클래스의 예측 분류 결과"],"metadata":{"id":"f4XeXQ7qSo_K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(y_test, y_pred))"],"metadata":{"id":"_W0DBoIK-Bho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#confusion matrix 시각화\n","\n","cm = confusion_matrix(y_test, y_pred, labels=K_clf.classes_)\n","\n","disp = ConfusionMatrixDisplay(confusion_matrix = cm,\n","                              display_labels = K_clf.classes_)\n","\n","fig, ax = plt.subplots(figsize=(10,10))\n","\n","disp.plot(ax=ax)\n","\n","plt.show()"],"metadata":{"id":"NAszkHXJSuQV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### K 결정하기"],"metadata":{"id":"A1Vz_iWDVz_Q"}},{"cell_type":"code","source":["# K=1부터 30까지 에러 계산하기\n","\n","error = []\n","\n","for i in range(1, 31):\n","    knn = KNeighborsClassifier(n_neighbors = i)\n","    knn.fit(X_train, y_train)\n","    pred_i = knn.predict(X_test)\n","    error.append(np.mean(pred_i != y_test))"],"metadata":{"id":"yqLiC_o2TkDA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["error"],"metadata":{"id":"NNlNYDXVYdUd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt"],"metadata":{"id":"LXKc0r4B8uby"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 7))\n","\n","plt.plot(range(1, 30), error,\n","         color='blue', linestyle='solid', marker='D', markerfacecolor='red')\n","\n","plt.title('Error by K')\n","\n","plt.xlabel('K')\n","\n","plt.ylabel('Average Error')\n","\n","plt.show()"],"metadata":{"id":"9XlvDLflTj8v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#accuracy만 출력할 경우\n","\n","from sklearn.metrics import accuracy_score\n","\n","acc = accuracy_score(y_pred,y_test)\n","\n","print('accuracy :', format(acc, '.4f'))"],"metadata":{"id":"rzyQ_67dTjs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_list = []\n","\n","for i in range(10, 21):\n","    knn = KNeighborsClassifier(n_neighbors = i)\n","    knn.fit(X_train, y_train)\n","    pred_i = knn.predict(X_test)\n","    accu = accuracy_score(pred_i,y_test)\n","    acc_list.append(accu)"],"metadata":{"id":"B8pcZ57kTjPs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["acc_list"],"metadata":{"id":"BTCZ5O9-TitX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure(figsize=(10, 7))\n","\n","plt.plot(range(10, 21), acc_list, \n","         color='blue', linestyle='solid', marker='D', markerfacecolor='red')\n","\n","plt.title('Accuracy by K')\n","\n","plt.xlabel('K')\n","\n","plt.ylabel('Accuracy')\n","\n","plt.show()"],"metadata":{"id":"q657e7-UYKrx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Maximum accuracy:\", max(acc_list), \"at K =\", acc_list.index(max(acc_list)) + 10)"],"metadata":{"id":"H1ugoOSsY_fb"},"execution_count":null,"outputs":[]}]}